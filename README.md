# Analysis of the State and Evolution of Empirical Research in Requirements Engineering
The project contains the analysis of the state and evolution of empirical research in requirements engineering and is supplementary material for the paper "*Divide and Conquer the EmpiRE: A Community-Maintained Body of Knowledge of Empirical Research in Requirements Engineering*", submitted to the [17th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement](https://conf.researchr.org/home/esem-2023).

<!--Binder link to the tailored forming analysis notebook:
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/okarras/Jupyter-Notebooks/HEAD?labpath=%2FTailoredFormingAnalysis%2Ftf_orkg.ipynb)--> 

## Context
Empirical research in Requirements Engineering (RE) has become an important topic and research area. Over the years, several researchers examined how empirical research in RE is "currently" conducted and how it should be conducted in the future by presenting snapshots of the "current" state of empirical research in RE and, more generally, in Software Engineering (SE). These researchers share the same goal of synthesizing a comprehensive, current, and long-term available overview of the state and evolution of empirical research in RE and SE. Although they share the same goal, use similar methods, i.e., (systematic) literature reviews or systematic mapping studies, and even examine overlapping periods, venues, and themes, they have not collaborated to build on and update previous work. **Lack of collaboration and updating are known challenges of literature reviews.** Overcoming these challenges is critical to ensure the quality, reliability, and timeliness of research findings from literature reviews.

## Motivation
Current research addresses the above challenges by focusing on when and how to update (systematic) literature reviews in SE and its subfields. While these works provide social and economic decision support and guidance for updating literature reviews, **the central problem is the unavailability of the extracted and analyzed data**, corresponding to open science in SE. Unavailable data complicates collaboration among researchers in updating a literature review as the entire data collection, extraction, and analysis must be repeated and expanded for a comprehensive review. Researchers need adequate technical support in the form of infrastructures and services to achieve sustainable literature reviews with all available data. These infrastructures must ensure that the data is Findable, Accessible, Interoperable, and Reusable (FAIR) over the long term following the FAIR data principles. For this purpose, the data must be organized in a flexible, fine-grained, context-sensitive, and semantic representation to be understandable, processable, and useful to humans and machines. Over the last decade, Knowledge Graphs (KGs) became an emerging technology in industry and academia as they enable this versatile data representation. Besides well-known KGs for encyclopedic and factual data, such as [DBpedia](https://www.dbpedia.org/) and [WikiData](https://www.wikidata.org), using so-called Research Knowledge Graphs (RKGs) for scientific data is a rather new approach. RKGs include bibliographic metadata, e.g., titles, authors, and venues, as well as scientific data, e.g., research designs, methods, and results. They are a promising technology to sustainably organize scientific data, e.g., extracted and analyzed data of literature reviews, as a body of knowledge that can be built, published, maintained, (re)used, updated, and expanded in a long-term and collaborative manner.

## Objective
**Our longterm objective is to develop a body of knowledge that synthesizes a comprehensive, current, and long-term available overview of the state and evolution of empirical research in RE**. For this purpose, we start to explore using RKGs as technical infrastructure for building, publishing, (re)using, updating, and expanding an initial body of knowledge of empirical research in RE (EmpiRE), that the research community can maintain by *dividing* the efforts to *conquer* the EmpiRE. In particular, we explore using the Open Research Knowledge Graph ([ORKG](https://orkg.org/)), a cross-domain and cross-topic RKG that provides accompanying services using intertwined human and machine intelligence by combining manual crowdsourcing and automated approaches to organize scientific data. With this work, we lay the foundation for such a comprehensive, current, and long-term available overview of the state and evolution of empirical research in RE by building, publishing, and evaluating an initial informed and reflected body of knowledge of empirical research in RE.

## Approach
<p align="center">
    <img src="Figures/approach.png" width="600"/>
    
</p>
<p align="center">
    <em>Research approach for developing, publishing, and evaluating an intial informed and reflected body of knowledge of empirical research in RE.</em>
</p>

Our research approach consists of three steps: Data collection, Data extraction, and Data analysis. So far, **we collected 411 papers** published in the research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 2006 to 2022. **We extracted and organized their scientific data**, i.a., research paradigm, research design, empirical method (data collection and data analysis), and bibliographic metadata using a developed [ORKG template](https://orkg.org/template/R186491). ORKG templates allow specifying the structure of descriptions of papers similar to SHACL shapes. In this way, we determined which data should be extracted and ensured that all the descriptions of papers are consistent and comparable to **build and publish an initial informed and reflected body of knowledge of empirical research in RE**.

In this Jupyter Notebook, we perform the data analysis of the developed body of knowledge of empirical research in RE, which has two purposes:

(1) We want to evaluate the body of knowledge concerning its coverage of the curated topic.

(2) We want to get first insights into the state and evolution of empirical research in RE by analyzing the developed body of knowledge.

The data analysis is based on competency questions regarding empirical research in all fields of SE, including RE, derived from the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30). [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) describe their vision of the role of empirical methods in all fields of SE, including RE, for the current period of 2020 – 2025 by comparing the **"current" state of practice (2007)** with their **target state (2020 - 2025)**. We analyzed these descriptions and derived a total of [77 competency questions](competency-questions.xlsx). For each competency question, we assessed whether we can answer the question with the developed body of knowledge. Subsequently, we specified the answerable competency questions as [SPARQL](https://www.w3.org/TR/sparql11-query/) queries to retrieve and analyze the data from the [ORKG](https://orkg.org/). In this way, **we obtain answers to the competency questions and thus gain first insights into the state and evolution of empirical research in RE**.

### Results
**Coverage:**

Regarding the coverage of the curated topic by the initial body of knowledge, we can state that we are able to answer 16 of the 77 competence questions (21%) using the extracted data. While this number of answered competency questions substantiates an acceptable coverage of the body of knowledge, the need to expand the [ORKG template](https://orkg.org/template/R186491) to extract and organize more data required to answer the open competency questions is clearly evident. However, we did not focus on building and publishing an already comprehensive body of knowledge of empirical research in RE that can be used to answer as many competency questions as possible. Instead, we focused on a concrete use case to show how RKGs, and in particular the ORKG, can be used as a technical infrastructure for organizing scientific data for long-term availability to enable the collaborative building, publication, (re-)use, updating, and expansion of a community-maintained body of knowledge of empirical research in RE.

**State and evolution of empirical research in RE:**

Regarding the state and evolution of empirical research in RE by analyzing the developed body of knowledge, we can report a positive development with respect to the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30). We found that the proportion of papers with an empirical study increases over time with a current average proportion of 94.3% for the **target state (2020 - 2025)**. For data collection, researchers frequently and constantly use the established empricial methods *experiment*, *secondary research*, and *survey* with current average proportions of 35.7% (*experiment*), 40% (*secondary research*), and 18.7% (*survey*) for the **target state (2020 -2025)**. We also found that the use of the empirical method *case study*, whose increased use is envisioned, decreases over time with a current proportion of 22.3% for the **target state (2020 - 2025)**. Despite the decrease, the emprical method *case study* is actually used more frequently than than surveys on average in the **target state (2020 - 2025)**. Furthermore, this decrease represents a positive development of the empirical research in RE, as researchers seem to be more aware of the definition of a case study and therefore use the term more purposefully than in the past. This finding is consistent with the conclusion of [Wohlin](https://doi.org/10.1016/j.infsof.2021.106514) who stated that the term *case study* is often misused in software engineering. Consequently, empirical research that is called as a *case study* in recent years appears to actually be a *case study*. For data analysis, researchers mainly and constantly use *descriptive statistics* with a proportion of 92% overall and for the **target state (2020 - 2025)**. In constrast, the use of *inferential statistics* with a proportion of 23% overall and 26.3% for the **target state (2020 - 2025)** is rather small. Regarding the general use of empirical methods, we found that the number of empirical methods used for data collection and data analysis in a single papers increases over time, with *three to four empirical methods* most frequently used in one paper. For the **target state (2020 - 2025)**, researchers mainly use *three to even five empirical methods* in a single paper with average proportions of 22% (*three empirical methods used*), 25.3% (*four empirical methods used*), and 26.7% (*five empirical methods used*). This increase in the number of empirical methods used shows a shift as envisioned towards the use of several empirical methods and thus the collection and analysis of data from different perspectives to synthesize evidence. In addition to the empirical methods used, we also found a positive development with regard to the reporting of important information of the experimental design. For the **target state (2020 - 2025)**, the proportion of papers reporting *threats to validity*, providing *raw data and supplementary materials*, and highlighting their *research questions and answers* steadily increase over time with average proportions of 91.3% (*threats to validity*), 71.3% (*raw data and supplementary materials*), and 23.7% (*highlighted research questions and answer*) respectively 53% (*highlighted research question and answer hidden in the running text*). 

Besides all the positive developments with respect to the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), we also identified needs for future improvements of empirical research in RE. While [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envisioned an increased use of *action research, we found that the proportion of *action research* is small over the entire timeframe analyzed (2006 - 2022) with an average proportion of only 1.4%. For the **target state (2020 - 2025)**, no paper reported the use of *action research*. According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), more *case studies* and *action research* are especially needed to ensure the industrial relevance of empirical research. This part of the vision is not yet nearly achieved. Regarding the reporting of threats to validity, we found two issues for future improvement. First, a proportion of 31.1% of the analyzed papers reporting threats to validity *only mentioned threats to validity* without any further classification of the types of the reported threats to validity. Although the general reporting of threats to validity is a positive development, the lack of classification of the reported threats to validity makes it difficult for a reader to have a clear overview of whether the threats to validity have been discussed comprehensively. In the future, researchers must endeavor to communicate their threats to validity more transparently by clearly classifying each of the threats mentioned with regard to their type of validity. Second, the proportion of threats to *conclusion validity* with 19.3% is rather small compared to the other mainly discussed types of valdity (*external validity*: 62.9%, *internal validity*: 59.1%, and *construct validity*: 50%). Therefore, researchers need to make more effort to comprehensively discuss the validity of their empirical research by also addressing the conclusion valditiy similar to the other types of validity. Regarding data analysis, the proportion of paper using *inferential statistics* is small with a proportion of only 26.2% for the **target state (2020 - 2025)**. For a mature use of statistical methods as envisioned by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), researchers have to deal more with *inferential statistics* and include them in the data analysis of their empirical research.

### Conclusion
First of all, we want to remark that the generalizability of our findings is limited as the body of knowledge of empirical reserach in RE built and published so far is only an initial version due to the limited analysis of the 411 papers from the research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 2006 to 2022. This conference is the largest international conference in the research field of RE where a large number of established researchers in this field regularly publish high-quality, peer-reviewed papers.
Therefore, the papers analyzed are a representative for the target population of all papers in RE, but they still form only a small subset. Nevertheless, the results provide important insights into the state and evolution of empirical research in RE published in [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings). For this reason, we consider the current scope of our use case to be appropriate to show how RKGs, and in particular the ORKG, can be used as a technical infrastructure for organizing scientific data for long-term availability to enable the collaborative building, publication, (re-)use, updating, and expansion of a community-maintained body of knowledge of empirical research in RE.

Using the ORKG, the extracted data is not available as usual in a spreadsheet, which is, at best, published on a data repository, but in a publicly accessible knowledge graph. In this context, the ORKG is, to put it simply, a graph-based database with an easy-to-use and sustainably governed infrastructure that implements best practices, such as FAIR principles and versioning, with corresponding services to support researchers in organizing (acquiring, curating, publishing, and processing) of FAIR scientific data. As a result, this FAIR scientific data is available and accessible in the long term and can be understood, processed, and used by humans and machines. Thus, the research community can maintain, (re-)use, update, and expand the initial body of knowledge of empirical research in RE that we have built and published in a long-term and collaborative manner. For example, in case of possible errors in data extraction, anyone, and in the best case the authors themselves, can easily update the data. However, it is also possible to expand the body of knowledge by curating more papers using or even expanding the existing [ORKG template](https://orkg.org/template/R186491) to extract more data in a structured, consistent, and comparable way. In all these cases, anyone can (re-)use this Jupyter Notebook to reproduce the data analysis and its (updated) results. Using RKGs to organize scientific data helps to address two of the key challenges of literature reviews: **Lack of collaboration among researchers and updating existing literature reviews**. For this reason, we conclude that using RKGs represents a step in the right direction toward sustainable literature reviewsto ensure the quality, reliability, and timeliness of research findings for a successful long-term collaboration of researchers.

For our future work, we have a plan with short-, mid-, and long-term actions. As short-term actions, we are currently working on expanding the body of knowledge by describing more papers of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) with our existing [ORKG template](https://orkg.org/template/R186491). Our goal is to cover the entire research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 1994 - 2022 in the next months to get a comprehensive overview of the state and evolution of empirical research in RE at this conference. So far, we already curated 28 additional papers from 2005 whose extracted data still needs to be verified before it can be inlcuded in the data analysis. Furthermore, we plan establish a so-called [ORKG observatory](https://orkg.org/about/27/Observatories). An [ORKG observatory](https://orkg.org/about/27/Observatories) is a open group that anyone can join to organize scientific data on the topic of the observatory, thus building and expanding a community-maintained body of knowledge in the ORKG. We intend to establish an [ORKG observatory](https://orkg.org/about/27/Observatories) on "*Empirical Software Engineering*", which also includes our initial body of knowledge of empirical research in RE, in order to address a larger topic and thus generate more interest among potential contributors. As mid-term actions, we intend to write and publish an [ORKG review](https://orkg.org/about/16/Reviews) about the state and evolution of empirical research in RE, based initially on the complete collection of all papers from the research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 1994 - 2022. An [ORKG review](https://orkg.org/about/16/Reviews) is a special kind of literature review article as it is a so-called living document that the research community can maintain when underlying content in the ORKG changes due to updates or extensions. Besides the [ORKG review](https://orkg.org/about/16/Reviews), we also intend to expand the body of knowledge of emprical reserach in RE by including more papers from other important venues, such as the journal [Requirements Engineering](https://link.springer.com/journal/766/volumes-and-issues) or the [International Working Conference on Requirement Engineering: Foundation for Software Quality](https://link.springer.com/conference/refsq), to gain a more comprehensive overview of the state and evolution of empirical research in RE. As long-term action, it is necessary to expand the existing [ORKG template](https://orkg.org/template/R186491) to organize more extensive scientific data about empirical resarch in a structured, consistent, and comparable manner and thus to address the still open [competency questions](competency-questions.xlsx). With this plan, we are work towards maintaining, updating, and expanding our initial body of knowledge together with the research community by *dividing* the efforts to *conquer* the EmpiRE.
